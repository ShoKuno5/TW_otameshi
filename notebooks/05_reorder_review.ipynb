{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# レビューのソート\n",
    "\n",
    "適切な評価指標が必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリをインポート\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Jupyter Notebook用の設定\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのパス\n",
    "data_path = 'data/processed/android_cleaned_mecab_with_topics.csv'\n",
    "\n",
    "# データの読み込み\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# データの基本情報を確認\n",
    "print(f\"データサイズ: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "\n",
    "# 日付をdatetime型に変換\n",
    "# ISO8601形式に対応して日付を変換\n",
    "df['date'] = pd.to_datetime(df['date'], format='ISO8601', errors='coerce')\n",
    "\n",
    "# データ全体の最新の日付を取得\n",
    "latest_date = df['date'].max()\n",
    "\n",
    "# 各レビューに対して経過時間を計算（日数単位）\n",
    "df['elapsed_days'] = (latest_date - df['date']).dt.days\n",
    "\n",
    "# 経過日数が0の場合を防ぐために1日未満のデータを補正\n",
    "df['elapsed_days'] = df['elapsed_days'].replace(0, 1)\n",
    "\n",
    "# 共感性（Engagement）の計算\n",
    "df['engagement'] = df['thumbsUp'] / df['elapsed_days']\n",
    "\n",
    "# percentileを使って正規化\n",
    "\n",
    "qt = QuantileTransformer(output_distribution='uniform', random_state=0)\n",
    "df['engagement_quantile_normalized'] = qt.fit_transform(df[['engagement']])\n",
    "\n",
    "# 結果を確認\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# レビューの情報量を計算する\n",
    "# レビューの長さを文字数で計算\n",
    "\n",
    "# レビューの長さを計算\n",
    "df['review_length'] = df['text'].str.len()\n",
    "\n",
    "# レビューの長さをpercentileで正規化\n",
    "\n",
    "qt = QuantileTransformer(output_distribution='uniform', random_state=0)\n",
    "df['review_length_quantile_normalized'] = qt.fit_transform(df[['review_length']])\n",
    "                        \n",
    "# 結果を確認\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "# mecabrcのパスを明示的に指定\n",
    "mecab = MeCab.Tagger(\"-d /opt/homebrew/lib/mecab/dic/mecab-ipadic-neologd -r /opt/homebrew/etc/mecabrc\")\n",
    "ochasen_tagger = MeCab.Tagger(\"-d /opt/homebrew/lib/mecab/dic/mecab-ipadic-neologd -r /opt/homebrew/etc/mecabrc\")\n",
    "def lemmatize_entities(entity_list, ochasen_tagger):\n",
    "    for i, entity in enumerate(entity_list):\n",
    "        node = ochasen_tagger.parse(entity)\n",
    "        lines = node.split(\"\\n\")\n",
    "        for line in lines[:-2]:  # 最後のEOSや空行を無視\n",
    "            fields = line.split(\"\\t\")\n",
    "            print(fields)  # デバッグ用\n",
    "            \n",
    "            if len(fields) >= 2:\n",
    "                # fields[1]をカンマで分割\n",
    "                features = fields[1].split(\",\")\n",
    "                # features[6]が原形（基本形）\n",
    "                if len(features) > 6:\n",
    "                    entity_list[i] = features[6]\n",
    "    return entity_list\n",
    "\n",
    "def extract_effective_keywords(review_document, ochasen_tagger):\n",
    "    review_keywords_list = {'proper_nouns': [], 'numbers': []}\n",
    "    node = ochasen_tagger.parse(review_document)\n",
    "    lines = node.split(\"\\n\")\n",
    "\n",
    "    for line in lines:\n",
    "        if line == \"EOS\" or line.strip() == \"\":\n",
    "            continue\n",
    "        fields = line.split(\"\\t\")\n",
    "        if len(fields) < 2:\n",
    "            continue\n",
    "\n",
    "        pos_info = fields[1].split(\",\")\n",
    "        pos_major = pos_info[0]  # 名詞,動詞,形容詞など\n",
    "        pos_sub1 = pos_info[1]   # 固有名詞,一般 などの細分類\n",
    "\n",
    "        if pos_major == \"名詞\" and pos_sub1 == \"固有名詞\":\n",
    "            review_keywords_list['proper_nouns'].append(fields[0])\n",
    "        elif pos_major == \"名詞\" and pos_sub1 == \"数\":\n",
    "            review_keywords_list['numbers'].append(fields[0])\n",
    "\n",
    "    return review_keywords_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "review_document = '2024.09.12 アップデート後、動画が凄くスムーズに再生されるので凄く感動しています、それに貯蓄ポイントに利息が付いて来るなんて、ポイントを貯める事に熱が入るのは間違いない。今後も使いやすいアプリ目指して頑張ってください。'\n",
    "keywords = extract_effective_keywords(review_document, ochasen_tagger)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのpositive_review, negative_reviewに対して形態素解析を実行，結果を新たなカラムとして追加\n",
    "\n",
    "df['negative_review_concreteness'] = df['negative_review'].apply(lambda x: extract_effective_keywords(x, ochasen_tagger))\n",
    "\n",
    "\n",
    "# negative_review_concretenessに含まれる個数をカウント\n",
    "\n",
    "df['negative_review_concreteness_count'] = df['negative_review_concreteness'].apply(lambda x: len(x['proper_nouns']) + len(x['numbers']))\n",
    "\n",
    "# 正規化\n",
    "\n",
    "qt = QuantileTransformer(output_distribution='uniform', random_state=0)\n",
    "df['negative_review_concreteness_quantile_normalized'] = qt.fit_transform(df[['negative_review_concreteness_count']])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from bertopic import BERTopic\n",
    "\n",
    "# モデルのロード\n",
    "topic_model = BERTopic.load('models/android_topic_model')\n",
    "\n",
    "# 特定のキーワードリスト\n",
    "keywords = [\"位置情報\", \"許可\"]\n",
    "\n",
    "# SentenceTransformerのembedding_modelにアクセスして埋め込みを生成\n",
    "keyword_embeddings = topic_model.embedding_model.embedding_model.encode(keywords)\n",
    "\n",
    "# 各negative reviewのembeddingを取得\n",
    "negative_review_embeddings = topic_model.embedding_model.embedding_model.encode(df['negative_review'])\n",
    "\n",
    "# dfに結果を格納\n",
    "df['negative_review_similarity'] = cosine_similarity(negative_review_embeddings, keyword_embeddings).max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# negative_reviewが\"-\"だけのものは，negative_review_similarityを0にする\n",
    "df.loc[df['negative_review'] == \"-\", 'negative_review_similarity'] = 0\n",
    "\n",
    "# 正規化\n",
    "\n",
    "qt = QuantileTransformer(output_distribution='uniform', random_state=0)\n",
    "df['negative_review_similarity_quantile_normalized'] = qt.fit_transform(df[['negative_review_similarity']])\n",
    "\n",
    "# negative_review_similarity_quantile_normalizedが高い順に表示\n",
    "df.sort_values('negative_review_similarity_quantile_normalized', ascending=False).head()\n",
    "\n",
    "# 結果を確認\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_probability, engagement_quantile_normalized, review_length_quantile_normalized, negative_review_concreteness_quantile_normalized, negative_review_similarity_quantile_normalizedを重み付けして，代表レビュースコアを計算\n",
    "\n",
    "# 重み付け\n",
    "topic_weight = 0.02\n",
    "engagement_weight = 0.05\n",
    "review_length_weight = 0.02\n",
    "negative_review_concreteness_weight = 0.01\n",
    "negative_review_similarity_weight = 0.9\n",
    "\n",
    "# 重み付けしたスコアを計算\n",
    "df['representative_review_score'] = (df['topic_probability'] * topic_weight) + (df['engagement_quantile_normalized'] * engagement_weight) + (df['review_length_quantile_normalized'] * review_length_weight) + (df['negative_review_concreteness_quantile_normalized'] * negative_review_concreteness_weight)\n",
    "\n",
    "# 正規化\n",
    "qt = QuantileTransformer(output_distribution='uniform', random_state=0)\n",
    "df['representative_review_score_quantile_normalized'] = qt.fit_transform(df[['representative_review_score']])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_topics,similarity=topic_model.find_topics(\"許可\",top_n=50)\n",
    "topic_model.get_topic(similar_topics[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各トピックの中で，thumbsupが最も多いレビューを取得\n",
    "\n",
    "# トピックごとにthumbsUpが最も多いレビューを取得\n",
    "most_liked_reviews = df.loc[df.groupby('topic')['thumbsUp'].idxmax()]\n",
    "\n",
    "# 結果を確認\n",
    "most_liked_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "# Topic 11 に該当するデータをフィルタリング\n",
    "topic_id = 11\n",
    "filtered_df = df[df['topic'] == topic_id].copy()\n",
    "\n",
    "# クエリ \"位置情報\" をベクトル化\n",
    "query = \"位置情報\"\n",
    "query_vector = topic_model.vectorizer_model.transform([query])\n",
    "\n",
    "# 類似度を計算して追加する関数\n",
    "def calculate_similarity(review):\n",
    "    # レビューが空の場合は類似度を 0 とする\n",
    "    if not review or len(review.strip()) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # レビューをベクトル化\n",
    "    review_vector = topic_model.vectorizer_model.transform([review])\n",
    "    \n",
    "    # クエリとのコサイン類似度を計算\n",
    "    similarity = cosine_similarity(query_vector, review_vector)\n",
    "    return similarity[0, 0]\n",
    "\n",
    "# 各 text に対して類似度を計算\n",
    "filtered_df['similarity'] = filtered_df['text'].apply(calculate_similarity)\n",
    "\n",
    "# 類似度スコアで上位n件を取得\n",
    "n = 5\n",
    "top_n_reviews = filtered_df.nlargest(n, 'similarity')\n",
    "\n",
    "# 上位5件の id と text を出力\n",
    "for idx, row in top_n_reviews.iterrows():\n",
    "    print(f\"ID: {row['id']}\")\n",
    "    print(f\"レビュー: {row['text']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トピックごとに thumbsUp と topic probability と review length の積を計算\n",
    "df['score'] = df['engagement_quantile_normalized'] + df['topic_probability'] + df['review_length_quantile_normalized']\n",
    "\n",
    "# トピックごとに score が最も大きいレビューを取得\n",
    "most_liked_reviews = df.loc[df.groupby('topic')['score'].idxmax()]\n",
    "\n",
    "# 結果を確認\n",
    "\n",
    "most_liked_reviews.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project-root-rWJ-GWg1-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
